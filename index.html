<!DOCTYPE html>
<html lang="en">
  <!-- Head -->
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    
    <!-- Metadata, OpenGraph and Schema.org -->

  <!-- Website verification -->
  
    <meta name="google-site-verification" content="">
  
  
  <!--
    Avoid warning on Google Chrome Error with Permissions-Policy header:
    Origin trial controlled feature not enabled: 'interest-cohort'.
    see https://stackoverflow.com/a/75119417
  -->
  <meta http-equiv="Permissions-Policy" content="interest-cohort=()">




<!-- Standard metadata -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<title>
  
  
    Stella Grasshof
  
</title>
<meta name="author" content="Stella Grasshof">
<meta name="description" content="">

  <meta name="keywords" content="machine learning, academic, university">










<!-- Bootstrap & MDB -->
<link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04">
<!-- <link rel="stylesheet" href="/assets/css/mdb.min.css?62a43d1430ddb46fc4886f9d0e3b49b8"> -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous">

<!-- Bootstrap Table -->


<!-- Fonts & Icons -->
<link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5">
<link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap">

<!-- Code Syntax Highlighting -->
<link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light">



<!-- Styles -->

<link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e">
<link rel="canonical" href="http://localhost:4000/">

<!-- Dark Mode -->

  <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark">
  <script src="/assets/js/theme.js?0afe9f0ae161375728f7bcc5eb5b4ab4"></script>


<!-- GeoJSON support via Leaflet -->


<!-- diff2html -->






  </head>

  <!-- Body -->
  <body class="fixed-top-nav ">
    <!-- Header -->
    <header>
  <!-- Nav Bar -->
  <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation">
    <div class="container">
      
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>

      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          

          <!-- About -->
          <li class="nav-item active">
            <a class="nav-link" href="/">About
              
                <span class="sr-only">(current)</span>
              
            </a>
          </li>

          <!-- Other pages -->
          
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
              
                <li class="nav-item ">
                  
                  <a class="nav-link" href="/projects/">Projects
                    
                  </a>
                </li>
              
            
          
            
              
                <li class="nav-item ">
                  
                  <a class="nav-link" href="/publications/">Publications
                    
                  </a>
                </li>
              
            
          
            
              
                <li class="nav-item ">
                  
                  <a class="nav-link" href="/studentprojects/">Student Projects
                    
                  </a>
                </li>
              
            
          
            
              
                <li class="nav-item ">
                  
                  <a class="nav-link" href="/teaching/">Teaching
                    
                  </a>
                </li>
              
            
          
            
              
                <li class="nav-item ">
                  
                  <a class="nav-link" href="/blog/">Blog
                    
                  </a>
                </li>
              
            
          
            
              
                <li class="nav-item ">
                  
                  <a class="nav-link" href="/cv/">CV
                    
                  </a>
                </li>
              
            
          
          
            <!-- Toogle theme mode -->
            <li class="toggle-container">
              <button id="light-toggle" title="Change theme">
                <i class="fa-solid fa-moon"></i>
                <i class="fa-solid fa-sun"></i>
              </button>
            </li>
          
        </ul>
      </div>
    </div>
  </nav>
  
    <!-- Scrolling Progress Bar -->
    <progress id="progress" value="0">
      <div class="progress-container">
        <span class="progress-bar"></span>
      </div>
    </progress>
  
</header>


    <!-- Content -->
    <div class="container mt-5" role="main">
      
        <div class="post">
  <header class="post-header">
    <h1 class="post-title">
      
        <span class="font-weight-bold">Stella</span> 
        Grasshof
      
    </h1>
    <p class="desc"><a href="#">Assistant Professor at IT University of Copenhagen</a></p>
  </header>

  <article>
    
      <div class="profile float-right">
        
          
          
          
          

<figure>
  <picture>
    <!-- Auto scaling with imagemagick -->
    <!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    -->
    
    <img src="/assets/img/prof_pic.jpg?658e8dc0bf8b9a09b36994abf9242099" class="img-fluid z-depth-1
      rounded" width="100%" height="auto" alt="prof_pic.jpg" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

  
</figure>

        
        
          <div class="more-info"></div>
        
      </div>
    

    <div class="clearfix">
<p>I am working as an Assistant Professor in the Data Science section at the <a href="https://en.itu.dk/" rel="external nofollow noopener" target="_blank">IT University of Copenhagen</a> and affiliated with the <a href="https://www.aicentre.dk/" rel="external nofollow noopener" target="_blank">Pioneer Centre for AI</a>. Additionally, I am an active member and board member of the <a href="https://lundbeckfonden.com/lfin" rel="external nofollow noopener" target="_blank">Lundbeck Foundation Investigator Network</a>.</p>

<p>My research focuses on  <strong>human-centred Machine Learning</strong>, particularly in the area of generative AI for visual data. I am working on developing models that can learn from and synthesize images, videos, and other complex data sources to analyse and synthesize human faces, human motion, and a variety of other visual patterns. While most of my current work is aimed at advancing applications in the mental health domain, my research extends across diverse visual fields, e.g. underwater images. I am collaborating with industry partners on cutting-edge challenges, contributing to innovative solutions.</p>

<p>I am grateful to be able to pursue my research in machine learning in the mental health domain with our PhD student Martin Trinhammer, who has a background in psychology. This work extents the grant I got from the Lundbeck Foundation about the same topic, where my collaboration with experts from the psychology domain is paramount. 
We aim at learning more about different mental disorders, to improve their diagnosis, personalize health care, and improve access. While this is challenging in itself, we are working on different aspects of ensuring privacy of the patient data.</p>

<p>To get a better understanding of my research and interests, please check my <a href="http://stellagrasshof.com/publications/" rel="external nofollow noopener" target="_blank">publications</a>, and <a href="http://stellagrasshof.com/studentprojects/" rel="external nofollow noopener" target="_blank">student projects</a>.</p>

<p>Currently, I am happily co-supervising the following three bright PhD students:</p>
<ul>
  <li>
<a href="https://pure.itu.dk/da/persons/leo-vitasovic" rel="external nofollow noopener" target="_blank">Leo Vitasovic</a> with <a href="https://pure.itu.dk/da/persons/sami-brandt" rel="external nofollow noopener" target="_blank">Sami S. Brandt</a>
</li>
  <li>
<a href="https://pure.itu.dk/da/persons/martin-lund-trinhammer" rel="external nofollow noopener" target="_blank">Martin Lund Trinhammer</a> with <a href="https://pure.itu.dk/da/persons/sami-brandt" rel="external nofollow noopener" target="_blank">Sami S. Brandt</a>
</li>
  <li>
<a href="https://pure.itu.dk/en/persons/magnus-ibh" rel="external nofollow noopener" target="_blank">Magnus Ibh</a> with <a href="https://pure.itu.dk/en/persons/dan-witzner-hansen" rel="external nofollow noopener" target="_blank">Dan Witzner Hansen</a> and <a href="https://vbn.aau.dk/da/persons/102245" rel="external nofollow noopener" target="_blank">Pascal Madeleine</a>
</li>
  <li>
<a href="https://www.linkedin.com/in/luiza-ribeiro-marnet-378259116" rel="external nofollow noopener" target="_blank">Luiza Ribeiro Marnet</a> with <a href="http://www.itu.dk/people/wasowski/" rel="external nofollow noopener" target="_blank">Andrzej Wąsowski</a> and <a href="https://www.linkedin.com/in/yurybrodskiy/" rel="external nofollow noopener" target="_blank">Yury Brodskiy</a>
</li>
</ul>

<p>The first PhD student <a href="https://www.linkedin.com/in/haasrene/?originalSubdomain=dk" rel="external nofollow noopener" target="_blank">René Haas</a>, whom I co-supervised with <a href="https://pure.itu.dk/da/persons/sami-brandt" rel="external nofollow noopener" target="_blank">Sami S. Brandt</a>, finished end of 2023, and delivered an excellent thesis. More details about his work can be found <a href="http://stellagrasshof.com/projects/3_project/" rel="external nofollow noopener" target="_blank">here</a>.</p>

</div>

    <!-- News -->
    
      <h2>
        <a href="/news/" style="color: inherit">news</a>
      </h2>
      <div class="news">
  
    
    <div class="table-responsive" style="max-height: 60vw">
      <table class="table table-sm table-borderless">
        
        
        
          <tr>
            <th scope="row" style="width: 20%">Apr 29, 2025</th>
            <td>
              
                Today, I returned from another inspiring meeting with the <a href="https://lundbeckfonden.com/lfin" rel="external nofollow noopener" target="_blank">Lundbeck Foundation Investigator Network (LFIN)</a>. We organized a 2-day workshop about science communication and open science. One of my delightful duties as training and development director.

              
            </td>
          </tr>
        
          <tr>
            <th scope="row" style="width: 20%">Mar 27, 2025</th>
            <td>
              
                On Monday, 31.03.2025 Magnus is defending his PhD thesis <a href="https://en.itu.dk/Research/PhD-Programme/PhD-Defences/PhD-Defences-2025/March/Magnus-Ibh" rel="external nofollow noopener" target="_blank">Skeleton-Based Modeling in Badminton</a> at ITU, hence ending our joint academic journey.

              
            </td>
          </tr>
        
          <tr>
            <th scope="row" style="width: 20%">Mar 14, 2025</th>
            <td>
              
                As part of the event series “Last Fridays Talks” at the <a href="https://www.aicentre.dk/" rel="external nofollow noopener" target="_blank">pioneercentre for AI</a>, I will present <a href="https://www.aicentre.dk/events/last-fridays-talks-fine-grained-analysis" rel="external nofollow noopener" target="_blank">Insights into Generation and Analysis of Faces</a> on 28th March.

              
            </td>
          </tr>
        
          <tr>
            <th scope="row" style="width: 20%">Mar 11, 2025</th>
            <td>
              
                Today, Luiza is defending her PhD thesis <a href="https://en.itu.dk/Research/PhD-Programme/PhD-Defences/PhD-Defences-2025/March/Luiza-Ribeiro-Marnet" rel="external nofollow noopener" target="_blank">“Vision-based classification for underwater safety critical applications”</a> at ITU! It was a great pleasure being part of her journey.

              
            </td>
          </tr>
        
          <tr>
            <th scope="row" style="width: 20%">Jan 31, 2025</th>
            <td>
              
                I spent some days at the LFIN Winterschool where I gave a talk about data analysis and patient studies.

              
            </td>
          </tr>
        
      </table>
    </div>
  
</div>

    

    <!-- Latest posts -->
    
      <h2>
        <a href="/blog/" style="color: inherit">latest posts</a>
      </h2>
      <div class="news">
  
    
    <div class="table-responsive" style="max-height: 60vw">
      <table class="table table-sm table-borderless">
        
        
        
          <tr>
            <th scope="row" style="width: 20%">Jan 03, 2025</th>
            <td>
              
                <a class="news-title" href="/blog/2025/grateful/">Being Grateful</a>
              
            </td>
          </tr>
        
          <tr>
            <th scope="row" style="width: 20%">Oct 25, 2024</th>
            <td>
              
                <a class="news-title" href="/blog/2024/poster/">How I create scientific posters</a>
              
            </td>
          </tr>
        
          <tr>
            <th scope="row" style="width: 20%">Jun 17, 2024</th>
            <td>
              
                <a class="news-title" href="/blog/2024/tools/">Tools which make your life easier</a>
              
            </td>
          </tr>
        
      </table>
    </div>
  
</div>

    

    <!-- Selected papers -->
    
      <h2>
        <a href="/publications/" style="color: inherit">selected publications</a>
      </h2>
      <div class="publications">
  <ol class="bibliography">
<li>
<div class="row">
  
    <div class="col-sm-2 preview">
      
        
          
          

<figure>
  <picture>
    <!-- Auto scaling with imagemagick -->
    <!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    -->
    
    <img src="/assets/img/publication_preview/2024_10_synthnet.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="2024_10_synthnet.png" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

  
</figure>

        
      
    </div>
  

  <!-- Entry bib key -->
  <div id="ertner_2024_mmisports" class="col-sm-8">
    <!-- Title -->
    <div class="title">SynthNet: Leveraging Synthetic Data for 3D Trajectory Estimation from Monocular Video</div>
    <!-- Author -->
    <div class="author">
      

      
      Morten Holck
            Ertner
          , Sofus Schou
            Konglevoll
          , Magnus
            Ibh
          , and
        <span class="more-authors" title="click to view 1 more author" onclick="
              var element = $(this);
              element.attr('title', '');
              var more_authors_text = element.text() == '1 more author' ? 'Stella Graßhof' : '1 more author';
              var cursorPosition = 0;
              var textAdder = setInterval(function(){
                element.text(more_authors_text.substring(0, cursorPosition + 1));
                if (++cursorPosition == more_authors_text.length){
                  clearInterval(textAdder);
                }
            }, '10');
          ">1 more author</span>
      
    </div>

    <!-- Journal/Book title and date -->
    
    
    
    
    
    
    
    <div class="periodical">
      <em>In Proceedings of the 7th ACM International Workshop on Multimedia Content Analysis in Sports</em> ,  Oct 2024
    </div>
    <div class="periodical">
      
    </div>

    <!-- Links/Buttons -->
    <div class="links">
      
        <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      
      
      
      
      
        
          <a href="/assets/pdf/2024_ertner_mmisport.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
        
      
      
      
      
      
      
      
      
        <a href="https://www.growkudos.com/publications/10.1145%25252F3689061.3689073/reader" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a>
      
    </div>
    
      
      
      
      
    

    
      <!-- Hidden abstract block -->
      <div class="abstract hidden">
        <p>Reconstructing 3D trajectories from video is often cumbersome and expensive, relying on complex or multi-camera setups. This paper proposes SynthNet, an end-to-end pipeline for monocular reconstruction of 3D tennis ball trajectories. The pipeline consists of two parts: Hit and bounce detection and 3D trajectory reconstruction. The hit and bounce detection is performed by a GRU-based model, which segments the videos into individual shots. Next, a fully connected neural network reconstructs the 3D trajectory through a novel physics-based training approach relying on purely synthetic training data. Instability in the training loop caused by relying on Euler-time integration and camera projections is circumvented by our synthetic approach, which directly calculates loss from estimated initial conditions, improving stability and performance. In experiments, SynthNet is compared to an existing reconstruction baseline on a number of conventional and customized metrics defined to validate our synthetic approach. SynthNet outperforms the baseline based on our own proposed metrics and in a qualitative inspection of the reconstructed 3D trajectories.</p>
      </div>
    

    

    
  </div>
</div>
</li>
<li>
<div class="row">
  
    <div class="col-sm-2 preview">
      
        
          
          

<figure>
  <picture>
    <!-- Auto scaling with imagemagick -->
    <!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    -->
    
    <img src="/assets/img/publication_preview/2024_magnus_cvpr.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="2024_magnus_cvpr.png" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

  
</figure>

        
      
    </div>
  

  <!-- Entry bib key -->
  <div id="ibh_tempose_2024" class="col-sm-8">
    <!-- Title -->
    <div class="title">A stroke of genius: Predicting the next move in badminton</div>
    <!-- Author -->
    <div class="author">
      

      
      Magnus
            Ibh
          , <em>Stella
            Graßhof</em>, and Dan
            Witzner
          
    </div>

    <!-- Journal/Book title and date -->
    
    
    
    
    
    
    
    <div class="periodical">
      <em>In 2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)</em> ,  Jun 2024
    </div>
    <div class="periodical">
      
    </div>

    <!-- Links/Buttons -->
    <div class="links">
      
        <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      
      
      
      
      
        
          <a href="/assets/pdf/2024_ibh_cvprws.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
        
      
      
      
      
      
      
      
      
        <a href="https://github.com/MagnusPetersenIbh/RallyTemPose-Predicting-the-next-stroke-in-badminton" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a>
      
    </div>
    
      
      
      
      
    

    
      <!-- Hidden abstract block -->
      <div class="abstract hidden">
        <p>This paper presents, RallyTemPose, a transformer encoder-decoder model for predicting future badminton strokes based on previous rally actions. The model uses court position, skeleton poses, and player-specific embeddings to learn stroke and player-specific latent representations in a spatiotemporal encoder module. The representations are then used to condition the subsequent strokes in a decoder module through rally-aware fusion blocks, which provide additional relevant strategic and technical considerations to make more informed predictions. RallyTemPose shows improved forecasting accuracy compared to traditional sequential methods on two real-world badminton datasets. The performance boost can also be attributed to the inclusion of improved stroke embeddings extracted from the latent representation of a pre-trained large-language model subjected to detailed text descriptions of stroke descriptions. In the discussion, the latent representations learned by the encoder module show useful properties regarding player analysis and comparisons.</p>
      </div>
    

    

    
  </div>
</div>
</li>
<li>
<div class="row">
  
    <div class="col-sm-2 preview">
      
        
          
          

<figure>
  <picture>
    <!-- Auto scaling with imagemagick -->
    <!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    -->
    
    <img src="/assets/img/publication_preview/2024_haas_fg.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="2024_haas_fg.png" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

  
</figure>

        
      
    </div>
  

  <!-- Entry bib key -->
  <div id="haas_discovering_2024" class="col-sm-8">
    <!-- Title -->
    <div class="title">Discovering Interpretable Directions in the Semantic Latent Space of Diffusion Models</div>
    <!-- Author -->
    <div class="author">
      

      
      René
            Haas
          , Inbar
            Huberman-Spiegelglas
          , Rotem
            Mulayoff
          , and
        <span class="more-authors" title="click to view 3 more authors" onclick="
              var element = $(this);
              element.attr('title', '');
              var more_authors_text = element.text() == '3 more authors' ? 'Sami Brandt, Stella Graßhof, Tomer Michaeli' : '3 more authors';
              var cursorPosition = 0;
              var textAdder = setInterval(function(){
                element.text(more_authors_text.substring(0, cursorPosition + 1));
                if (++cursorPosition == more_authors_text.length){
                  clearInterval(textAdder);
                }
            }, '10');
          ">3 more authors</span>
      
    </div>

    <!-- Journal/Book title and date -->
    
    
    
    
    
    
    
    <div class="periodical">
      <em>In 18th IEEE International Conference on Automatic Face and Gesture Recognition</em> ,  May 2024
    </div>
    <div class="periodical">
      
    </div>

    <!-- Links/Buttons -->
    <div class="links">
      
        <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      
      
      
      
      
        
          <a href="/assets/pdf/2024_haas_fg.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
        
      
      
      
      
      
      
        
          <a href="/assets/pdf/2024_haas_fg_poster.pdf" class="btn btn-sm z-depth-0" role="button">Poster</a>
        
      
      
      
        <a href="https://github.com/renhaa/semantic-diffusion" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a>
      
    </div>
    
      
      
      
      
    

    
      <!-- Hidden abstract block -->
      <div class="abstract hidden">
        <p>Denoising Diffusion Models (DDMs) have emerged as a strong competitor to Generative Adversarial Networks (GANs).
However, despite their widespread use in image synthesis and editing applications, their latent space is still not as well understood. Recently, a semantic latent space for DDMs, coined ‘h-space’, was shown to facilitate semantic image editing in a way reminiscent of GANs. The h-space is comprised of the bottleneck activations in the DDM’s denoiser across all timesteps of the diffusion process. In this paper, we explore the properties of h-space and propose several novel methods for finding meaningful semantic directions within it. We start by studying unsupervised methods for revealing interpretable semantic directions in pretrained DDMs. Specifically, we show that interpretable directions emerge as the principal components in the latent space. Additionally, we provide a novel method for discovering image-specific semantic directions by spectral analysis of the Jacobian of the denoiser w.r.t. the latent code. 
Next, we extend the analysis by finding directions in a supervised fashion in unconditional DDMs.
We demonstrate how such directions can be found by annotating generated samples with a domain-specific attribute classifier. 
We further show how to semantically disentangle the found directions by simple linear projection.
Our approaches are applicable without requiring any architectural modifications, text-based guidance, CLIP-based optimization, or model fine-tuning.</p>
      </div>
    

    

    
  </div>
</div>
</li>
<li>
<div class="row">
  
    <div class="col-sm-2 preview">
      
        
          
          

<figure>
  <picture>
    <!-- Auto scaling with imagemagick -->
    <!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    -->
    
    <img src="/assets/img/publication_preview/2023_magnus_cvpr2.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="2023_magnus_cvpr2.png" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

  
</figure>

        
      
    </div>
  

  <!-- Entry bib key -->
  <div id="ibh_tempose_2023" class="col-sm-8">
    <!-- Title -->
    <div class="title">TemPose: a new skeleton-based transformer model designed for fine-grained motion recognition in badminton</div>
    <!-- Author -->
    <div class="author">
      

      
      Magnus
            Ibh
          , <em>Stella
            Graßhof</em>, Dan
            Witzner
          , and
        <span class="more-authors" title="click to view 1 more author" onclick="
              var element = $(this);
              element.attr('title', '');
              var more_authors_text = element.text() == '1 more author' ? 'Pascal Madeleine' : '1 more author';
              var cursorPosition = 0;
              var textAdder = setInterval(function(){
                element.text(more_authors_text.substring(0, cursorPosition + 1));
                if (++cursorPosition == more_authors_text.length){
                  clearInterval(textAdder);
                }
            }, '10');
          ">1 more author</span>
      
    </div>

    <!-- Journal/Book title and date -->
    
    
    
    
    
    
    
    <div class="periodical">
      <em>In 2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)</em> ,  Jun 2023
    </div>
    <div class="periodical">
      ISSN: 2160-7516
    </div>

    <!-- Links/Buttons -->
    <div class="links">
      
        <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      
      
      
      
      
        
          <a href="/assets/pdf/2023_Ibh_cvprw_tempose.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
        
      
      
      
      
      
      
      
      
        <a href="https://github.com/MagnusPetersenIbh/TemPose-BadmintonActionRecognition" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a>
      
    </div>
    
      
      
      
      
    

    
      <!-- Hidden abstract block -->
      <div class="abstract hidden">
        <p>This paper presents TemPose, a novel skeleton-based transformer model designed for fine-grained motion recognition to improve understanding of the detailed player actions in badminton. The model utilizes multiple temporal and interaction layers to capture variable-length multi-person human actions while minimizing reliance on non-human visual context. TemPose is evaluated on two fine-grained badminton datasets, where it significantly outperforms other baseline models by incorporating additional input streams, such as the shuttlecock position, into the temporal transformer layers of the model. Additionally, TemPose demonstrates great versatility by achieving competitive results compared to other state-of-the-art skeleton-based models on the large-scale action recognition benchmark NTU RGB+D. Experiments are conducted to explore how different model parameter configurations affect Tem-Pose’s performance. Additionally, a qualitative analysis of the temporal attention maps suggests that the model learns to prioritize frames of specific poses relevant to different actions while formulating an intuition of each individual’s importance in the sequences. Overall, TemPose is an intuitive and versatile architecture that has the potential to be further developed and incorporated into other methods for managing human motion in sports with state-of-the-art results.</p>
      </div>
    

    

    
  </div>
</div>
</li>
<li>
<div class="row">
  
    <div class="col-sm-2 preview">
      
        
          
          

<figure>
  <picture>
    <!-- Auto scaling with imagemagick -->
    <!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    -->
    
    <img src="/assets/img/publication_preview/2023_rene_cvpr.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="2023_rene_cvpr.png" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

  
</figure>

        
      
    </div>
  

  <!-- Entry bib key -->
  <div id="haas_controllable_2023" class="col-sm-8">
    <!-- Title -->
    <div class="title">Controllable GAN Synthesis Using Non-Rigid Structure-from-Motion</div>
    <!-- Author -->
    <div class="author">
      

      
      René
            Haas
          , <em>Stella
            Graßhof</em>, and Sami S.
            Brandt
          
    </div>

    <!-- Journal/Book title and date -->
    
    
    
    
    
    
    
    <div class="periodical">
      <em>In 2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)</em> ,  Jun 2023
    </div>
    <div class="periodical">
      
    </div>

    <!-- Links/Buttons -->
    <div class="links">
      
        <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      
      
      
      
      
        
          <a href="/assets/pdf/2023_haas_cvprw.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
        
      
      
      
      
      
      
      
      
        <a href="https://github.com/renhaa/rankonegan" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a>
      
    </div>
    
      
      
      
      
    

    
      <!-- Hidden abstract block -->
      <div class="abstract hidden">
        <p>In this paper, we present an approach for combining non-rigid structure-from-motion (NRSfM) with deep generative models, and propose an efficient framework for discovering trajectories in the latent space of 2D GANs corresponding to changes in 3D geometry. Our approach uses recent advances in NRSfM and enables editing of the camera and non-rigid shape information associated with the latent codes without needing to retrain the generator. This formulation provides an implicit dense 3D reconstruction as it enables the image synthesis of novel shapes from arbitrary view angles and non-rigid structure. The method is built upon a sparse backbone, where a neural regressor is first trained to regress parameters describing the cameras and sparse non-rigid structure directly from the latent codes. The latent trajectories associated with changes in the camera and structure parameters are then identified by estimating the local inverse of the regressor in the neighborhood of a given latent code. The experiments show that our approach provides a versatile, systematic way to model, analyze, and edit the geometry and non-rigid structures of faces.</p>
      </div>
    

    

    
  </div>
</div>
</li>
<li>
<div class="row">
  
    <div class="col-sm-2 preview">
      
        
          
          

<figure>
  <picture>
    <!-- Auto scaling with imagemagick -->
    <!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    -->
    
    <img src="/assets/img/publication_preview/2021_grasshof_tpami.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="2021_grasshof_tpami.png" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

  
</figure>

        
      
    </div>
  

  <!-- Entry bib key -->
  <div id="grashof_multilinear_2021" class="col-sm-8">
    <!-- Title -->
    <div class="title">Multilinear Modelling of Faces and Expressions</div>
    <!-- Author -->
    <div class="author">
      

      
      <em>Stella
            Graßhof</em>, Hanno
            Ackermann
          , Sami Sebastian
            Brandt
          , and
        <span class="more-authors" title="click to view 1 more author" onclick="
              var element = $(this);
              element.attr('title', '');
              var more_authors_text = element.text() == '1 more author' ? 'Jörn Ostermann' : '1 more author';
              var cursorPosition = 0;
              var textAdder = setInterval(function(){
                element.text(more_authors_text.substring(0, cursorPosition + 1));
                if (++cursorPosition == more_authors_text.length){
                  clearInterval(textAdder);
                }
            }, '10');
          ">1 more author</span>
      
    </div>

    <!-- Journal/Book title and date -->
    
    
    
    
    
    
    
    <div class="periodical">
      <em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em>,  Oct 2021
    </div>
    <div class="periodical">
      
    </div>

    <!-- Links/Buttons -->
    <div class="links">
      
        <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      
      
      
      
      
        
          <a href="/assets/pdf/2021_grasshof_tpami.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
        
      
      
      
      
      
      
      
      
    </div>
    
      
      
      
      
    

    
      <!-- Hidden abstract block -->
      <div class="abstract hidden">
        <p>In this work, we present a new versatile 3D multilinear statistical face model, based on a tensor factorisation of 3D face scans, that decomposes the shapes into person and expression subspaces. Investigation of the expression subspace reveals an inherent low-dimensional substructure, and further, a star-shaped structure. This is due to two novel findings. (1) Increasing the strength of one emotion approximately forms a linear trajectory in the subspace. (2) All these trajectories intersect at a single point – not at the neutral expression as assumed by almost all prior works—but at an apathetic expression. We utilise these structural findings by reparameterising the expression subspace by the fourth-order moment tensor centred at the point of apathy. We propose a 3D face reconstruction method from single or multiple 2D projections by assuming an uncalibrated projective camera model. The non-linearity caused by the perspective projection can be neatly included into the model. The proposed algorithm separates person and expression subspaces convincingly, and enables flexible, natural modelling of expressions for a wide variety of human faces. Applying the method on independent faces showed that morphing between different persons and expressions can be performed without strong deformations.</p>
      </div>
    

    

    
  </div>
</div>
</li>
</ol>
</div>

    

    <!-- Social -->
    
      <div class="social">
        <div class="contact-icons">
  <a href="mailto:%73%74%67%72@%69%74%75.%64%6B" title="email"><i class="fa-solid fa-envelope"></i></a>




  <a href="https://orcid.org/0000-0002-6791-7425" title="ORCID" rel="external nofollow noopener" target="_blank"><i class="ai ai-orcid"></i></a>


  <a href="https://scholar.google.com/citations?user=kSuLm58AAAAJ&amp;hl" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a>


  <a href="https://www.semanticscholar.org/author/23620370" title="Semantic Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-semantic-scholar"></i></a>







  <a href="https://github.com/stellagra" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-github"></i></a>


  <a href="https://www.linkedin.com/in/stella-gra%C3%9Fhof-15202579" title="LinkedIn" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-linkedin"></i></a>


























</div>

        <div class="contact-note">The best way to reach out to me is email or linkedin.
</div>
      </div>
    
  </article>
</div>

      
    </div>

    <!-- Footer -->
    
  <footer class="fixed-bottom" role="contentinfo">
    <div class="container mt-0">
      © Copyright 2025
      Stella
      
      Grasshof. 
      
      
    </div>
  </footer>



    <!-- JavaScripts -->
    <!-- jQuery -->
<script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
<script src="/assets/js/bootstrap.bundle.min.js"></script>
<!-- <script src="/assets/js/mdb.min.js"></script> -->
<script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    
  <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script>
  <script defer src="/assets/js/masonry.js" type="text/javascript"></script>


    

    

    

    

    

    

    

    

  <!-- Medium Zoom JS -->
  <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script>
  <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script>



<!-- Bootstrap Table -->


<!-- Load Common JS -->
<script src="/assets/js/no_defer.js?2930004b8d7fcd0a8e00fdcfc8fc9f24"></script>
<script defer src="/assets/js/common.js?da39b660470d1ba6e6b8bf5f37070b6e"></script>
<script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script>

    
  <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script>


  <script async src="https://badge.dimensions.ai/badge.js"></script>


    
  <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams',
      },
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


    
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id="></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() {
      window.dataLayer.push(arguments);
    }
    gtag('js', new Date());
    gtag('config', '');
  </script>



    
  <!-- Scrolling Progress Bar -->
  <script type="text/javascript">
    /*
     * This JavaScript code has been adapted from the article
     * https://css-tricks.com/reading-position-indicator/ authored by Pankaj Parashar,
     * published on the website https://css-tricks.com on the 7th of May, 2014.
     * Couple of changes were made to the original code to make it compatible
     * with the `al-foio` theme.
     */
    const progressBar = $('#progress');
    /*
     * We set up the bar after all elements are done loading.
     * In some cases, if the images in the page are larger than the intended
     * size they'll have on the page, they'll be resized via CSS to accomodate
     * the desired size. This mistake, however, breaks the computations as the
     * scroll size is computed as soon as the elements finish loading.
     * To account for this, a minimal delay was introduced before computing the
     * values.
     */
    window.onload = function () {
      setTimeout(progressBarSetup, 50);
    };
    /*
     * We set up the bar according to the browser.
     * If the browser supports the progress element we use that.
     * Otherwise, we resize the bar thru CSS styling
     */
    function progressBarSetup() {
      if ('max' in document.createElement('progress')) {
        initializeProgressElement();
        $(document).on('scroll', function () {
          progressBar.attr({ value: getCurrentScrollPosition() });
        });
        $(window).on('resize', initializeProgressElement);
      } else {
        resizeProgressBar();
        $(document).on('scroll', resizeProgressBar);
        $(window).on('resize', resizeProgressBar);
      }
    }
    /*
     * The vertical scroll position is the same as the number of pixels that
     * are hidden from view above the scrollable area. Thus, a value > 0 is
     * how much the user has scrolled from the top
     */
    function getCurrentScrollPosition() {
      return $(window).scrollTop();
    }

    function initializeProgressElement() {
      let navbarHeight = $('#navbar').outerHeight(true);
      $('body').css({ 'padding-top': navbarHeight });
      $('progress-container').css({ 'padding-top': navbarHeight });
      progressBar.css({ top: navbarHeight });
      progressBar.attr({
        max: getDistanceToScroll(),
        value: getCurrentScrollPosition(),
      });
    }
    /*
     * The offset between the html document height and the browser viewport
     * height will be greater than zero if vertical scroll is possible.
     * This is the distance the user can scroll
     */
    function getDistanceToScroll() {
      return $(document).height() - $(window).height();
    }

    function resizeProgressBar() {
      progressBar.css({ width: getWidthPercentage() + '%' });
    }
    // The scroll ratio equals the percentage to resize the bar
    function getWidthPercentage() {
      return (getCurrentScrollPosition() / getDistanceToScroll()) * 100;
    }
  </script>


    

    

  </body>
</html>
